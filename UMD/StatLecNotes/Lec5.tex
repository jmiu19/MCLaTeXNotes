\documentclass[11pt,oneside]{book}

%%%%%%%%%%%%%%Include Packages%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{tikz}
\usepackage{mathtools}
\usepackage[legalpaper, margin=0.8in]{geometry}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{rsfso}
\usepackage{wasysym}
\usepackage{hyperref}
\usetikzlibrary{matrix, calc, arrows,
                arrows.meta, fit,
                positioning, quotes,
                shapes.geometric}


%%%%%%%%%%%%%%%Color%%%%%%%%%%%%%%%%%%%%%%%%%%
\definecolor{gray75}{gray}{0.75}
\definecolor{yellow}{RGB}{255,255,177}
\definecolor{pink}{RGB}{250,204,224}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%Theorem environments%%%%%%%%%%%%%%%%%%%
\newtheoremstyle{break}
  {\topsep}{\topsep}%
  {\itshape}{}%
  {\bfseries}{}%
  {\newline}{}%
\newtheoremstyle{newStyle}
  {\topsep}{\topsep}%
  {\rmfamily}{}%
  {\bfseries}{}%
  {\newline}{}%             % Theorem head spec
  \theoremstyle{newStyle}
\newtheorem{thm}{Theorem}[chapter]
\newtheorem{lem}{Lemma}[thm]
\newtheorem{axiom}[thm]{Axiom}
\newtheorem{prop}[lem]{Proposition}
\newtheorem{cor}[lem]{Corollary}
\newtheorem{defn}[thm]{Definition}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\spa}{\text{span}}
\newcommand{\pd}{\partial}
\newcommand{\that}[1]{\widetilde{#1}}
\newcommand{\vmat}[1]{\begin{vmatrix} #1 \end{vmatrix}}
\newcommand{\bmat}[1]{\begin{bmatrix} #1 \end{bmatrix}}
\newcommand{\pmat}[1]{\begin{pmatrix} #1 \end{pmatrix}}
\newcommand*{\Perm}[2]{{}^{#1}\!P_{#2}}
\newcommand*{\Comb}[2]{{}^{#1}C_{#2}}
\newcommand*{\dr}[5]{\draw ({#1}.east) --+ ({#4},{#5}) node[right] ({#2}) {{#3}};}




\newcommand{\note}{\color{red}Note: \color{black}}
\newcommand{\remark}{\color{blue}Remark: \color{black}}
\newcommand{\example}{\color{purple}Example: \color{black}}
\newcommand{\exercise}{\color{cyan}Exercise: \color{black}}





\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Stat410 Sum24 Lecture 5 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Continuous Random Variables}\\

Suppose $X$ is a random variable with cdf $F_X(x)$, that is $F_X(x) = P(X\leq x)$. We say $X$ is a continuous random variable provided that $F_X:\R\to \R$ is a continuous function.\\

A probability density function for a continuous random variable is a function $f_X:\R \to \R$ satisfying 
\begin{align*}
F_X(x) = P(X\leq x) = \int_{-\infty}^x f_X(t) \, dt\,.
\end{align*}
We note that: 
\begin{enumerate}
\item $f_X$ need not be a continuous function for $F_X$ to be continuous. 
\item $P(a\leq X\leq b) = P(X\text{ takes values in }[a,b]) = \int_a^b f_X(x)\, dx$.
\item $P(X=a) = P(a\leq x\leq a) = \int_a^a f_X(x) \, dx = 0$. That is, the probability that $X$ takes any fixed number equals to zero. 
\item Via the Fundamental Theorem of Calculus, the integration and differentiation are inverse operations, that is
\begin{align*}
\frac{d}{dx}\left( \int_a^x f(u)\, du\right) = f(x) \,,
\end{align*}
from which we obtain the following theorem:
\begin{thm}
If the cdf is differentiable, $F'(x) = f_X(x)$. That is, 
\begin{align*}
\frac{d}{dx}\int_{-\infty}^x f_X(t) \, dt = f_X(x)\,.
\end{align*}
\end{thm}
\item From (4), to calculate the pdf of $X$, we can first calculate the cdf $F_X(x)$ of $X$, then if $F_X(x)$ is dfferentiable, $f_X(x) = F'(x)$. 
\item We also note that the Leibniz Rule for differentiating an integral gives
\begin{align*}
\frac{d}{dx}\left( \int^{b(x)}_{a(x)}f(t)\, dt\right) = b'(x)\cdot f(b(x)) - a'(x) \cdot f(a(x))\,.
\end{align*} 
\end{enumerate}


\begin{thm}
Let $f:\R \to \R$ be a function satisfying $f_X(x) \geq 0$ for all $x$ and $\int_{-\infty}^\infty f(x)\, dx  =1$. Then $f(x)$ is a pdf of some random variable. On the other hand, if $f_X(x)$ is a pdf of $X$, then $f_X(x)$ satisfies $f_X(x) \geq 0$ for all $x$ and $\int_{-\infty}^\infty f(x)\, dx  =1$.\\
\end{thm}
\hfill\break

\textbf{Example}
Consider the function $f:\R\to \R$ defined by
\begin{align*}
f(x) = \begin{cases} x^2(1-x) & x\in (0,1) \\ 
0 &\text{otherwise}
\end{cases}
\end{align*}
We would like to find a constant $c$ such that $f_X = c\cdot f$ defines a pdf of a ramdom variable. First we notice that $f(x) = x^2(1-x) \geq 0$ whenever $x \in (0,1)$. Now we compute
\begin{align*}
\int_{-\infty}^\infty f(x) \, dx = \int_0^1 x^2(1-x)\, dx = \int_0^1 x^2 - x^3 \, dx = \left(\left. \frac{x^3}{3} - \frac{x^4}{4}\right) \right|_{0}^1 = \frac{1}{12}\,.
\end{align*}
Thus if $c=12$, $f_X = 12\cdot f$, then $f_X$ is a pdf of a random variable with the correct normalization. 
\begin{align*}
f_X(x) = \begin{cases} 12 \cdot x^2(1-x) & x\in (0,1) \\ 0 &\text{otherwise}\end{cases}\,.
\end{align*} 
In this case, we can calculate
\begin{align*}
F_X(x) = \int_{-\infty}^x f_X(u)\, du &= \int_{-\infty}^x 12 \cdot u^2(1-u)\, du\\
&= 12\cdot \lim_{c\to -\infty}\int_c^x u^2(1-u) \, du \\
&= 12 \cdot \lim_{c\to -\infty}\left( \left( \frac{x^3}{3}-\frac{x^4}{4}\right) - \left( \frac{c^3}{3} - \frac{c^4}{4}\right)\right) \\
&= 12\left( \frac{x^3}{3} - \frac{x^4}{4}\right)\,.
\end{align*}
Here we observer that $F_X'(x) = F_X(x)$. \\

\textbf{Example}:
Consider $X$ being a random variable with pdf $F_X$ and cdf $F_X$, and let $Y = 4X^5$ be a new random variable. To calculate the pdf of $Y$, we first note that in general $f_Y(x) \neq 4(f(x))^5$. For $y \in \R$, 
\begin{align*}
F_Y(y) = P(Y\leq y) = P(4X^5\leq y) = P(X^5\leq y/4) = P(X\leq (y/4)^{1/5}) = F_X((y/4)^{1/5})\,.
\end{align*}
Now, using chain rule we can compute
\begin{align*}
f_Y(y) = \frac{d}{dy}\left(F_Y(y)\right) 
&= \frac{d}{dy}\left( F_X((y/4)^{1/5})\right)=F'_X\left( (y/4)^{1/5}\right) \cdot (y/4)^{-4/5}/20\,.
\end{align*}
With $f_X$ defined by the last example, we obtain
\begin{align*}
F'_X\left(\left( \frac{y}{4}\right)^{1/5}\right) = f_x\left( \left(\frac{y}{4}\right)^{1/5}\right) = 12\cdot \left( \frac{y}{4}\right)^{2/5}\cdot \left( 1- \left( \frac{y}{4}\right)^{1/5}\right)\,,
\end{align*}
and thus
\begin{align*}
f_Y(y) = \begin{cases}
\frac{3}{5}\cdot \left( \frac{y}{4}\right)^{-2/5}\cdot \left( 1- \left( \frac{y}{4}\right)^{1/5}\right) & y \in (0,1)\\
0 &\text{otherwise}
\end{cases}\,.
\end{align*}

\newpage
\textbf{Parameters Attached to Continuous Variables}\\
Suppose $X$ is a continuous random variable with pdf $f_X(x)$. 
\begin{enumerate}
\item The expected value of $X$ is given by \begin{align*}
E(X)  = \mu_X = \int_{-\infty}^\infty x\, f_X(x)\, dx\,.
\end{align*}
\item If $Y = h(X)$, then 
\begin{align*}
E(Y) = E(h(X)) = \int_{-\infty}^\infty h(x) \cdot f_X(x) \, dx = \int_{-\infty}^\infty y\cdot f_Y(y) \, dy\,.
\end{align*}
\item The variance of $X$ is defined by 
\begin{align*}
\sigma_X^2 = V(X) = \int_{-\infty}^{\infty}(x-\mu_X)^2 \cdot f_X(x) \, dx \,.
\end{align*}
Note that $V(X) = E(X^2) - E(X)$ still holds. 
\item The moment generating function is defined by 
\begin{align*}
M_X(t) = E(e^{tX}) = \int_{-\infty}^\infty e^{tx} \cdot f_X(x) \, dx\,.
\end{align*}
\item For $\alpha \in (0 ,1)$, $x_\alpha$ is the $\alpha^\text{th}$ critical value for $X$ is $x_\alpha$ satisfies $P(X\geq x_\alpha) = \alpha$, which holds iff $1-P(X\leq x_\alpha) = \alpha$, iff $P(X\leq x_\alpha) = (1-\alpha)$, iff $F_X(x_\alpha) = 1-\alpha$. 
\item For $p \in (0,1)$, $n_p$ is called the $p^\text{th}$ percentile provided that $P(X\leq n_p) = p$, which is equivalent to $F_X(n_p) = p$. We note that $\alpha^\text{th}$ critical value is the same as the $(1-\alpha)^{\text{th}}$ percentile. 
\end{enumerate}


\end{document}

